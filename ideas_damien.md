Idées du PDF:
1) How does the order in which we see the training data influence the result?
2) How do different optimization variants affect generalization (test error)?
3) How well do zero-order optimization methods do for ML applications, compared to standard first-order
methods?
4) Federated learning or decentralized learning with different data distributions per participant (non-iid per
participant).
5) Meta-Learning: Can you learn the learning rate? The importance of each datapoint? The direction or
curvature?

Autres idées:
1) Effect of gradient clipping on optimization:
   - Does gradient clipping help finding good local minima? 
   - How sensitive are different optimizers to gradient clipping?
   - Is there a relation between the model size and the performance of gradient clipping?
2) Same as 1. but for warm-up steps.