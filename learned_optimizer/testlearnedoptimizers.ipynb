{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyPUEQ9cKfqUCUQj5SiAbLS6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"9tXQ9OLGMy5u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748359117240,"user_tz":-120,"elapsed":298933,"user":{"displayName":"Alpha Beta","userId":"05277748414569037045"}},"outputId":"739f1b0f-6dad-4799-c6c6-3e88ca8f9e24"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 9.91M/9.91M [00:00<00:00, 43.2MB/s]\n","100%|██████████| 28.9k/28.9k [00:00<00:00, 1.19MB/s]\n","100%|██████████| 1.65M/1.65M [00:00<00:00, 10.6MB/s]\n","100%|██████████| 4.54k/4.54k [00:00<00:00, 11.4MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Meta Epoch 0, Batch 0, Final Loss: 17494.3086\n","Meta Epoch 0, Batch 100, Final Loss: 29273.3789\n","Meta Epoch 0, Batch 200, Final Loss: 35057.8945\n","Meta Epoch 0, Batch 300, Final Loss: 33405.4297\n","Meta Epoch 0, Batch 400, Final Loss: 37830.6172\n","Meta Epoch 0, Batch 500, Final Loss: 24990.5508\n","Meta Epoch 0, Batch 600, Final Loss: 20747.6191\n","Meta Epoch 0, Batch 700, Final Loss: 36504.0938\n","Meta Epoch 0, Batch 800, Final Loss: 37557.1250\n","Meta Epoch 0, Batch 900, Final Loss: 45898.2891\n","Meta Epoch 0, Batch 1000, Final Loss: 39327.5078\n","Meta Epoch 0, Batch 1100, Final Loss: 41892.1680\n","Meta Epoch 0, Batch 1200, Final Loss: 43841.2383\n","Meta Epoch 0, Batch 1300, Final Loss: 32619.2402\n","Meta Epoch 0, Batch 1400, Final Loss: 22824.2227\n","Meta Epoch 0, Batch 1500, Final Loss: 31394.1523\n","Meta Epoch 0, Batch 1600, Final Loss: 22481.7812\n","Meta Epoch 0, Batch 1700, Final Loss: 37762.8086\n","Meta Epoch 0, Batch 1800, Final Loss: 37023.3203\n","Meta Epoch 1, Batch 0, Final Loss: 32645.6836\n","Meta Epoch 1, Batch 100, Final Loss: 20863.0176\n","Meta Epoch 1, Batch 200, Final Loss: 39731.0703\n","Meta Epoch 1, Batch 300, Final Loss: 25800.7812\n","Meta Epoch 1, Batch 400, Final Loss: 53455.1328\n","Meta Epoch 1, Batch 500, Final Loss: 44832.4023\n","Meta Epoch 1, Batch 600, Final Loss: 36431.3477\n","Meta Epoch 1, Batch 700, Final Loss: 32830.0977\n","Meta Epoch 1, Batch 800, Final Loss: 33718.6914\n","Meta Epoch 1, Batch 900, Final Loss: 27352.1543\n","Meta Epoch 1, Batch 1000, Final Loss: 42945.1992\n","Meta Epoch 1, Batch 1100, Final Loss: 48596.1562\n","Meta Epoch 1, Batch 1200, Final Loss: 25576.6855\n","Meta Epoch 1, Batch 1300, Final Loss: 27380.0020\n","Meta Epoch 1, Batch 1400, Final Loss: 22309.8242\n","Meta Epoch 1, Batch 1500, Final Loss: 53494.5234\n","Meta Epoch 1, Batch 1600, Final Loss: 39001.6406\n","Meta Epoch 1, Batch 1700, Final Loss: 26074.7461\n","Meta Epoch 1, Batch 1800, Final Loss: 23963.8242\n","Meta Epoch 2, Batch 0, Final Loss: 30819.0273\n","Meta Epoch 2, Batch 100, Final Loss: 27957.0059\n","Meta Epoch 2, Batch 200, Final Loss: 38760.1133\n","Meta Epoch 2, Batch 300, Final Loss: 20207.7559\n","Meta Epoch 2, Batch 400, Final Loss: 26727.1719\n","Meta Epoch 2, Batch 500, Final Loss: 45464.9648\n","Meta Epoch 2, Batch 600, Final Loss: 36141.2227\n","Meta Epoch 2, Batch 700, Final Loss: 31665.6191\n","Meta Epoch 2, Batch 800, Final Loss: 23225.8438\n","Meta Epoch 2, Batch 900, Final Loss: 46313.3516\n","Meta Epoch 2, Batch 1000, Final Loss: 32330.4629\n","Meta Epoch 2, Batch 1100, Final Loss: 26823.6367\n","Meta Epoch 2, Batch 1200, Final Loss: 35981.5273\n","Meta Epoch 2, Batch 1300, Final Loss: 40704.7070\n","Meta Epoch 2, Batch 1400, Final Loss: 37990.8477\n","Meta Epoch 2, Batch 1500, Final Loss: 28405.7969\n","Meta Epoch 2, Batch 1600, Final Loss: 22487.4648\n","Meta Epoch 2, Batch 1700, Final Loss: 54547.8789\n","Meta Epoch 2, Batch 1800, Final Loss: 29928.6152\n","Meta Epoch 3, Batch 0, Final Loss: 40224.7891\n","Meta Epoch 3, Batch 100, Final Loss: 26637.2051\n","Meta Epoch 3, Batch 200, Final Loss: 20818.0742\n","Meta Epoch 3, Batch 300, Final Loss: 34993.7539\n","Meta Epoch 3, Batch 400, Final Loss: 33414.5859\n","Meta Epoch 3, Batch 500, Final Loss: 37580.9961\n","Meta Epoch 3, Batch 600, Final Loss: 36545.8398\n","Meta Epoch 3, Batch 700, Final Loss: 36174.7773\n","Meta Epoch 3, Batch 800, Final Loss: 38407.8984\n","Meta Epoch 3, Batch 900, Final Loss: 34507.8711\n","Meta Epoch 3, Batch 1000, Final Loss: 37283.2773\n","Meta Epoch 3, Batch 1100, Final Loss: 46598.6172\n","Meta Epoch 3, Batch 1200, Final Loss: 31433.1328\n","Meta Epoch 3, Batch 1300, Final Loss: 31501.6523\n","Meta Epoch 3, Batch 1400, Final Loss: 40314.3281\n","Meta Epoch 3, Batch 1500, Final Loss: 32856.0000\n","Meta Epoch 3, Batch 1600, Final Loss: 49156.0703\n","Meta Epoch 3, Batch 1700, Final Loss: 21900.7207\n","Meta Epoch 3, Batch 1800, Final Loss: 28289.2559\n","Meta Epoch 4, Batch 0, Final Loss: 34699.3047\n","Meta Epoch 4, Batch 100, Final Loss: 39431.2344\n","Meta Epoch 4, Batch 200, Final Loss: 42913.2891\n","Meta Epoch 4, Batch 300, Final Loss: 43479.0586\n","Meta Epoch 4, Batch 400, Final Loss: 38304.8633\n","Meta Epoch 4, Batch 500, Final Loss: 33958.9609\n","Meta Epoch 4, Batch 600, Final Loss: 16737.4355\n","Meta Epoch 4, Batch 700, Final Loss: 32864.4219\n","Meta Epoch 4, Batch 800, Final Loss: 38986.0117\n","Meta Epoch 4, Batch 900, Final Loss: 47145.6250\n","Meta Epoch 4, Batch 1000, Final Loss: 23637.0156\n","Meta Epoch 4, Batch 1100, Final Loss: 28397.7051\n","Meta Epoch 4, Batch 1200, Final Loss: 25127.9043\n","Meta Epoch 4, Batch 1300, Final Loss: 36407.7734\n","Meta Epoch 4, Batch 1400, Final Loss: 40309.7773\n","Meta Epoch 4, Batch 1500, Final Loss: 44369.0195\n","Meta Epoch 4, Batch 1600, Final Loss: 31601.7715\n","Meta Epoch 4, Batch 1700, Final Loss: 32209.0039\n","Meta Epoch 4, Batch 1800, Final Loss: 55640.3633\n","✅ Entraînement du learned optimizer terminé.\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","# --- Dataset MNIST ---\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","train_loader = DataLoader(datasets.MNIST(root='./data', train=True, download=True, transform=transform), batch_size=32, shuffle=True)\n","\n","# --- Modèle cible : un MLP simple ---\n","class MLP(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(28*28, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, 10)\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","# --- Learned Optimizer : un petit LSTM qui apprend les deltas ---\n","class LearnedOptimizer(nn.Module):\n","    def __init__(self, hidden_size=20):\n","        super().__init__()\n","        self.lstm = nn.LSTMCell(1, hidden_size)\n","        self.linear = nn.Linear(hidden_size, 1)\n","\n","    def forward(self, grad, state):\n","        grad = grad.view(-1, 1)\n","        hx, cx = state\n","        hx, cx = self.lstm(grad, (hx, cx))\n","        delta = self.linear(hx)\n","        return delta.view(-1), (hx, cx)\n","\n","    def init_state(self, num_params):\n","        device = next(self.parameters()).device\n","        return (torch.zeros(num_params, self.lstm.hidden_size, device=device),\n","                torch.zeros(num_params, self.lstm.hidden_size, device=device))\n","\n","# --- Meta-Training : entraîner le learned optimizer ---\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","meta_optimizer = LearnedOptimizer().to(device)\n","meta_optim = torch.optim.Adam(meta_optimizer.parameters(), lr=1e-3)\n","\n","for meta_epoch in range(5):  # Nombre d'époques meta\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","\n","        # Réinitialiser le modèle cible\n","        model = MLP().to(device)\n","        params = [p for p in model.parameters()]\n","        flat_params = torch.cat([p.data.view(-1) for p in params])\n","\n","        state = meta_optimizer.init_state(flat_params.numel())\n","\n","        # Inner loop : optimiser le MLP avec le learned optimizer\n","        for inner_step in range(20):  # Nombre d'étapes d'optimisation interne\n","            model.zero_grad()\n","            output = model(data)\n","            loss = F.cross_entropy(output, target)\n","            grads = torch.autograd.grad(loss, params, create_graph=True)\n","            grads_flat = torch.cat([g.view(-1) for g in grads])\n","\n","            # Update avec le learned optimizer\n","            delta, state = meta_optimizer(grads_flat.detach(), state)\n","            idx = 0\n","            for p in params:\n","                numel = p.numel()\n","                p.data = p.data - delta[idx:idx+numel].view_as(p)\n","                idx += numel\n","\n","        # Outer loss = perte finale après 20 steps\n","        final_output = model(data)\n","        final_loss = F.cross_entropy(final_output, target)\n","\n","        # Backprop à travers l'optimizer\n","        meta_optim.zero_grad()\n","        final_loss.backward()\n","        meta_optim.step()\n","\n","        if batch_idx % 100 == 0:\n","            print(f\"Meta Epoch {meta_epoch}, Batch {batch_idx}, Final Loss: {final_loss.item():.4f}\")\n","\n","print(\"✅ Entraînement du learned optimizer terminé.\")\n"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","# --- Dataset MNIST ---\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","train_loader = DataLoader(datasets.MNIST(root='./data', train=True, download=True, transform=transform), batch_size=16, shuffle=True)\n","\n","# --- MLP model ---\n","class MLP(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(28*28, 64),  # Reduced hidden size\n","            nn.ReLU(),\n","            nn.Linear(64, 10)\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","# --- Learned Optimizer ---\n","class LearnedOptimizer(nn.Module):\n","    def __init__(self, hidden_size=5):  # Smaller hidden size\n","        super().__init__()\n","        self.lstm = nn.LSTMCell(1, hidden_size)\n","        self.linear = nn.Linear(hidden_size, 1)\n","\n","    def forward(self, grad, state):\n","        grad = grad.view(-1, 1)\n","        hx, cx = state\n","        hx, cx = self.lstm(grad, (hx, cx))\n","        delta = self.linear(hx)\n","        return delta.view(-1), (hx, cx)\n","\n","    def init_state(self, num_params):\n","        # Store state on CPU to save GPU memory\n","        device = torch.device('cpu')\n","        return (torch.zeros(num_params, self.lstm.hidden_size, device=device),\n","                torch.zeros(num_params, self.lstm.hidden_size, device=device))\n","\n","# --- Meta-training the optimizer ---\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","meta_optimizer = LearnedOptimizer().to(device)\n","meta_optim = torch.optim.Adam(meta_optimizer.parameters(), lr=1e-3)\n","\n","for meta_epoch in range(3):  # Fewer meta-epochs\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","\n","        model = MLP().to(device)\n","        params = [p for p in model.parameters()]\n","        flat_params = torch.cat([p.data.view(-1) for p in params])\n","\n","        state = meta_optimizer.init_state(flat_params.numel())\n","\n","        for inner_step in range(10):  # Shorter unroll for memory\n","            model.zero_grad()\n","            output = model(data)\n","            loss = F.cross_entropy(output, target)\n","            grads = torch.autograd.grad(loss, params, create_graph=True)\n","            grads_flat = torch.cat([g.view(-1) for g in grads])\n","\n","            # Update on CPU, send back to GPU\n","            delta, state = meta_optimizer(grads_flat.detach().cpu(), state)\n","            delta = delta.to(device)\n","\n","            idx = 0\n","            for p in params:\n","                numel = p.numel()\n","                p.data = p.data - delta[idx:idx+numel].view_as(p)\n","                idx += numel\n","\n","        # Outer loss = loss after unroll\n","        final_output = model(data)\n","        final_loss = F.cross_entropy(final_output, target)\n","\n","        meta_optim.zero_grad()\n","        final_loss.backward()\n","        meta_optim.step()\n","\n","        if batch_idx % 100 == 0:\n","            print(f\"Meta Epoch {meta_epoch}, Batch {batch_idx}, Final Loss: {final_loss.item():.4f}\")\n","\n","print(\"✅ Meta-training of learned optimizer complete.\")\n","\n","# --- Evaluation: MNIST Accuracy ---\n","def evaluate_accuracy(model, data_loader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data, target in data_loader:\n","            data, target = data.to(device), target.to(device)\n","            outputs = model(data)\n","            _, predicted = torch.max(outputs, 1)\n","            correct += (predicted == target).sum().item()\n","            total += target.size(0)\n","    return correct / total\n","\n","test_loader_mnist = DataLoader(datasets.MNIST(root='./data', train=False, transform=transform), batch_size=128, shuffle=False)\n","\n","# Evaluate the trained MLP with the learned optimizer (on MNIST)\n","test_model = MLP().to(device)\n","params = [p for p in test_model.parameters()]\n","flat_params = torch.cat([p.data.view(-1) for p in params])\n","state = meta_optimizer.init_state(flat_params.numel())\n","\n","# Run a few optimization steps on MNIST test data\n","for batch_idx, (data, target) in enumerate(test_loader_mnist):\n","    data, target = data.to(device), target.to(device)\n","\n","    for inner_step in range(10):\n","        test_model.zero_grad()\n","        output = test_model(data)\n","        loss = F.cross_entropy(output, target)\n","        grads = torch.autograd.grad(loss, params, create_graph=False)\n","        grads_flat = torch.cat([g.view(-1) for g in grads])\n","\n","        delta, state = meta_optimizer(grads_flat.detach().cpu(), state)\n","        delta = delta.to(device)\n","\n","        idx = 0\n","        for p in params:\n","            numel = p.numel()\n","            p.data = p.data - delta[idx:idx+numel].view_as(p)\n","            idx += numel\n","\n","    if batch_idx > 20:  # Just test a few batches\n","        break\n","\n","accuracy_mnist = evaluate_accuracy(test_model, test_loader_mnist)\n","print(f\"✅ Accuracy on MNIST with learned optimizer: {accuracy_mnist * 100:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367},"id":"B5ygty-fUtBH","executionInfo":{"status":"error","timestamp":1748360147924,"user_tz":-120,"elapsed":29,"user":{"displayName":"Alpha Beta","userId":"05277748414569037045"}},"outputId":"026a7b5d-67ee-4758-b12c-0a19579034c2"},"execution_count":5,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-209aaf81503d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Update on CPU, send back to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_flat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-209aaf81503d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, grad, state)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1704\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_batched\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1706\u001b[0;31m         ret = _VF.lstm_cell(\n\u001b[0m\u001b[1;32m   1707\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m             \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"]}]},{"cell_type":"code","source":["# === Évaluation sur MNIST ===\n","\n","# DataLoader MNIST Test Set\n","test_loader = DataLoader(datasets.MNIST(root='./data', train=False, transform=transform), batch_size=128, shuffle=False)\n","\n","# Nouveau modèle à optimiser\n","test_model = MLP().to(device)\n","params = [p for p in test_model.parameters()]\n","flat_params = torch.cat([p.data.view(-1) for p in params])\n","state = meta_optimizer.init_state(flat_params.numel())\n","\n","# Inner loop d'optimisation sur le test set\n","for batch_idx, (data, target) in enumerate(test_loader):\n","    data, target = data.to(device), target.to(device)\n","\n","    for inner_step in range(20):  # Nombre d'étapes d'optimisation avec le learned optimizer\n","        test_model.zero_grad()\n","        output = test_model(data)\n","        loss = F.cross_entropy(output, target)\n","        grads = torch.autograd.grad(loss, params, create_graph=False)\n","        grads_flat = torch.cat([g.view(-1) for g in grads])\n","\n","        delta, state = meta_optimizer(grads_flat.detach(), state)\n","        idx = 0\n","        for p in params:\n","            numel = p.numel()\n","            p.data = p.data - delta[idx:idx+numel].view_as(p)\n","            idx += numel\n","\n","    if batch_idx > 30:  # Évaluer sur seulement quelques batches pour éviter d'exploser la RAM\n","        break\n","\n","# Évaluer l'accuracy finale\n","def evaluate_accuracy(model, data_loader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data, target in data_loader:\n","            data, target = data.to(device), target.to(device)\n","            outputs = model(data)\n","            _, predicted = torch.max(outputs, 1)\n","            correct += (predicted == target).sum().item()\n","            total += target.size(0)\n","    return correct / total\n","\n","accuracy = evaluate_accuracy(test_model, test_loader)\n","print(f\"✅ Accuracy du modèle optimisé par le learned optimizer: {accuracy * 100:.2f}%\")\n"],"metadata":{"id":"DFA45A-dd7x_","executionInfo":{"status":"error","timestamp":1748361530612,"user_tz":-120,"elapsed":18,"user":{"displayName":"Alpha Beta","userId":"05277748414569037045"}},"outputId":"465e349c-978a-4832-9dc5-32bdde225a1d","colab":{"base_uri":"https://localhost:8080/","height":367}},"execution_count":6,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-a662b8c23a20>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mgrads_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_flat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-209aaf81503d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, grad, state)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1704\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_batched\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1706\u001b[0;31m         ret = _VF.lstm_cell(\n\u001b[0m\u001b[1;32m   1707\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m             \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)"]}]}]}