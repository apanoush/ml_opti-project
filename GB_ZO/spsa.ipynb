{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8ecdd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spsa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcf51b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.7029954e-17,  1.0000000e+00])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x:np.ndarray)-> float:\n",
    "    return x[0]**2 + (x[1]-1)**2\n",
    "\n",
    "x = np.linspace(-5, 5, 10)\n",
    "x= [1,2]\n",
    "spsa.minimize(f, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd13950b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package spsa:\n",
      "\n",
      "NAME\n",
      "    spsa - Simultaneous Perturbation Stochastic Optimization (SPSA)\n",
      "\n",
      "DESCRIPTION\n",
      "    The purpose of this package is to provide multivariable optimizers\n",
      "    using SPSA. Although other optimizers exist, not many implement\n",
      "    SPSA, which has various pros and cons. Additionally, SPSA has\n",
      "    few requirements so that you don't have to install large packages\n",
      "    like scipy just to optimize a function.\n",
      "    \n",
      "    Usage\n",
      "    ------\n",
      "    Synchronous Functions:\n",
      "        x = spsa.maximize(f, x)\n",
      "        x = spsa.minimize(f, x)\n",
      "    \n",
      "        for variables in spsa.iterator.maximize(f, x):\n",
      "            print(variables)\n",
      "    \n",
      "        for variables in spsa.iterator.minimize(f, x):\n",
      "            print(variables)\n",
      "    \n",
      "    Example\n",
      "    --------\n",
      "        import numpy as np\n",
      "        import spsa\n",
      "    \n",
      "        # Squared distance to 0.\n",
      "        def sphere(x: np.ndarray) -> float:\n",
      "            return np.linalg.norm(x) ** 2\n",
      "    \n",
      "        # Attempt to find the minimum.\n",
      "        print(spsa.minimize(sphere, [1, 2, 3]))\n",
      "    \n",
      "        # Sample output:\n",
      "        #     [-5.50452777e-21 -9.48070248e-21  9.78726993e-21]\n",
      "    \n",
      "    Asynchronous Optimization\n",
      "    --------------------------\n",
      "    \n",
      "    Asynchronous Functions:\n",
      "        # spsa.aio - Asynchronous IO.\n",
      "        # Useful for:\n",
      "        #     IO-bound functions.\n",
      "        #     Functions running in executors.\n",
      "        #     Running `spsa` asynchronously with other code (non-blocking).\n",
      "        # See `help(spsa.aio)` for more details.\n",
      "    \n",
      "        x = await spsa.aio.maximize(async_def_f, x)\n",
      "        x = await spsa.aio.minimize(async_def_f, x)\n",
      "    \n",
      "        async for variables in spsa.aio.iterator.maximize(async_def_f, x):\n",
      "            print(variables)\n",
      "    \n",
      "        async for variables in spsa.aio.iterator.minimize(async_def_f, x):\n",
      "            print(variables)\n",
      "    \n",
      "    Synchronous Functions with Multiprocessing:\n",
      "        # spsa.amp - Asynchronous Multiprocessing.\n",
      "        # Useful for:\n",
      "        #     Running `spsa` asynchronously with other code (non-blocking).\n",
      "        #     Running `spsa` in an executor for efficiently running multiple at a time.\n",
      "        #     Not for improving a single `spsa` call.\n",
      "        # See `help(spsa.amp)` for more details.\n",
      "    \n",
      "        x = await spsa.amp.maximize(def_f, x)\n",
      "        x = await spsa.amp.minimize(def_f, x)\n",
      "    \n",
      "        async for variables in spsa.amp.iterator.maximize(def_f, x):\n",
      "            print(variables)\n",
      "    \n",
      "        async for variables in spsa.amp.iterator.minimize(def_f, x):\n",
      "            print(variables)\n",
      "    \n",
      "    Why use SPSA?\n",
      "    --------------\n",
      "    \n",
      "    ### Fast Convergence\n",
      "    \n",
      "    SPSA rapidly converges in a way similar to gradient descent. Unlike other black-box algorithms, SPSA is a rapid local optimization algorithm.\n",
      "    \n",
      "    ### Black-Box Derivative-Free\n",
      "    \n",
      "    SPSA does not require anything beyond the function being optimized. Unlike gradient descent, the derivative is not necessary.\n",
      "    \n",
      "    ### Stochastic Functions\n",
      "    \n",
      "    SPSA does not require the function to be completely accurate. If a randomized approximation of the function is easier to compute, SPSA usually converges just as well. Unlike stochastic tunneling, SPSA is not easily tricked into converging to points which randomly produced optimal values when the average value is suboptimal.\n",
      "    \n",
      "    ### High-Dimensional Problems\n",
      "    \n",
      "    SPSA is applicable to problems with many dimensions. Unlike most other black-box algorithms, SPSA converges well in many dimensions.\n",
      "    \n",
      "    ### Efficient Iterations\n",
      "    \n",
      "    SPSA uses only a few function calls per iteration plus vector operations. Unlike other black-box algorithms, the number of function calls per iteration does not scale with the dimensions of the problem.\n",
      "    \n",
      "    ### Efficient Parallelization\n",
      "    \n",
      "    SPSA is easily parallelized in several ways. `spsa.aio` performs parallel calls to the objective function each iteration and `spsa.amp` allows the SPSA algorithm itself to be parallelized.\n",
      "    \n",
      "    ### Integer Constraints\n",
      "    \n",
      "    SPSA can easily be applied to integer-constrained problems by rounding the input. In fact the provided implementation includes automatic tuning for the perturbations, which will automatically increase the distance between function calls until the arguments are about an integer apart from each other in order to observe a difference in output.\n",
      "    \n",
      "    ### Code Complexity\n",
      "    \n",
      "    SPSA requires less than 100 lines of code. Although this implementation includes more features, it is still less than 200 lines of code. This is unlike some other algorithms, such as Bayesian optimization, which may take several hundred more lines of code.\n",
      "    \n",
      "    SPSA also works entirely off of vector operations (not even matrix operations) and coin-flipping rng. This makes the source code easily transferable to other languages.\n",
      "    \n",
      "    Why use this implementation of SPSA?\n",
      "    -------------------------------------\n",
      "    \n",
      "    ### Learning Rate Tuning\n",
      "    \n",
      "    This implementation includes learning rate tuning, whereas most other implementations employ learning rate scheduling. With learning rate tuning, the learning rate is automatically optimized every iteration, at the cost of a few more calculations. With learning rate scheduling, the learning rate follows a predetermined sequence of values which usually decay to `0`. In theory, a decaying learning rate ensures eventual convergence if the function is noisy. In practice, we have found that a tuned learning rate, even in the presence of noise, can actually perform just as well if not better. After all, it is impossible to run an infinite number of iterations. Instead, it is usually faster to optimize the learning rate every iteration. Furthermore, this makes the learning rate more robust, allowing it to speed up when it can or rapidly slow down if it should.\n",
      "    \n",
      "    This implementation uses a simple tuning algorithm which updates the learning rate every iteration using only 2 additional function calls. Furthermore, the tuning algorithm is robust against stochastic functions and momentum. This means `f(x +- lr * dx)` is not optimized in terms of `lr`, but rather it looks ahead at future iterations to account for momentum while also considering the approximate amount of noise in the objective function.\n",
      "    \n",
      "    ### Perturbation Size Tuning\n",
      "    \n",
      "    This implementation includes perturbation size tuning, whereas most other implementations employ perturbation size scheduling. With perturbation size tuning, the perturbation size is automatically updated every iteration, at the cost of a few more calculations. With perturbation size scheduling, the perturbation size follows a predetermined sequence of values which usually decay to `0`. In theory, a decaying perturbation size ensures eventual convergence to the gradient if the function is noisy. In practice, we have found that a tuned perturbation size, especially in the presence of noise, performs better. This is because the noise in the objective function is amplified by a division by the perturbation size, causing small perturbations to be incredibly noisy. This implementation automatically scales the perturbation size based on the noise in the objective function, which ensures the noise are usually not so drastic that SPSA may diverge randomly on its own.\n",
      "    \n",
      "    ### Adaptive Momentum (Adam)\n",
      "    \n",
      "    This implementation includes the Adam method, whereas most other implementations do not. Each component is rescaled according to how large the gradient is in that dimension, which accelerates convergence in flatter directions while stabilizing convergence in steep directions.\n",
      "    \n",
      "    Furthermore, the perturbation size is scaled using the Adam method. This helps distribute the error in the gradient instead of only having an accurate estimate of the gradient in steep directions and an extremely inaccurate estimate of the gradient in flat directions. This may improve convergence in high-dimensional problems or with functions with greatly varying gradient components.\n",
      "    \n",
      "    ### Basin-Hopping\n",
      "    \n",
      "    For functions with many local minima, the `spsa.with_input_noise` function (including its `spsa.aio` and `spsa.amp` variants) provides ways to perform basin-hopping to an extent. By replacing the objective function with a stochastic estimate of the objective function over entire regions, local minima are removed, encouraging SPSA to converge to more globalized minima instead.\n",
      "    \n",
      "    ### Iterators\n",
      "    \n",
      "    For every optimizer, an iterator variant is also provided which exposes most of the variables inside of the optimizer. This enables users to track the progress of the optimizer instead of just relying on the final result as well as implement custom termination algorithms.\n",
      "    \n",
      "    ### Asynchronous Computations\n",
      "    \n",
      "    For every optimizer, an asynchronous variant is also provided which allows SPSA to be ran with asynchronous code. This enables various forms of parallelism or even just simple concurrency if SPSA needs to run concurrently with other code instead of blocking other asynchronous code from running.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _defaults\n",
      "    _spsa\n",
      "    _utils\n",
      "    aio (package)\n",
      "    amp (package)\n",
      "    iterator\n",
      "    random (package)\n",
      "\n",
      "FUNCTIONS\n",
      "    maximize(f: Callable[[numpy.ndarray], float], x: Union[numpy.ndarray, float, Sequence[float], Sequence[Sequence[float]], Sequence[Sequence[Sequence[float]]], Sequence[Sequence[Sequence[Sequence[float]]]], Sequence[Sequence[Sequence[Sequence[Sequence[float]]]]]], /, *, adam: bool = True, iterations: int = 10000, lr: Optional[float] = None, lr_decay: float = 0.001, lr_power: float = 0.5, px: Optional[float] = None, px_decay: float = 0.01, px_power: float = 0.161, momentum: float = 0.97, beta: float = 0.999, epsilon: float = 1e-07) -> numpy.ndarray\n",
      "        Implementation of the SPSA optimization algorithm for maximizing an objective function.\n",
      "        \n",
      "        See `help(spsa.minimize)` for documentation.\n",
      "    \n",
      "    minimize(f: Callable[[numpy.ndarray], float], x: Union[numpy.ndarray, float, Sequence[float], Sequence[Sequence[float]], Sequence[Sequence[Sequence[float]]], Sequence[Sequence[Sequence[Sequence[float]]]], Sequence[Sequence[Sequence[Sequence[Sequence[float]]]]]], /, *, adam: bool = True, iterations: int = 10000, lr: Optional[float] = None, lr_decay: float = 0.001, lr_power: float = 0.5, px: Optional[float] = None, px_decay: float = 0.01, px_power: float = 0.161, momentum: float = 0.97, beta: float = 0.999, epsilon: float = 1e-07) -> numpy.ndarray\n",
      "        Implementation of the SPSA optimization algorithm for minimizing an objective function.\n",
      "        \n",
      "        See `help(spsa)` for additional information.\n",
      "        \n",
      "        Defining Objective Functions\n",
      "        -----------------------------\n",
      "        Defining your objective function f appropriately can significantly change how well SPSA performs.\n",
      "        Here are some tips and tricks on how to define good objective functions.\n",
      "        \n",
      "            Detectable Changes:\n",
      "                SPSA requires changes in inputs to lead to changes in outputs.\n",
      "                Otherwise SPSA will be unable to determine how inputs should change.\n",
      "        \n",
      "                This isn't possible for all problems. Some may require other algorithms\n",
      "                e.g. Bayesian optimization or genetic algorithms. Some may need specialized\n",
      "                algorithms for the specific situation.\n",
      "        \n",
      "                If the objective function is noisy then SPSA will increase its change in input\n",
      "                until a significant change in output is detected i.e. the result isn't just noise.\n",
      "        \n",
      "                NOTE: SPSA assumes that the result y = f(x) has at least 1e-64 * y noise, so if\n",
      "                      there is no change in y, then the change in x automatically increases to try\n",
      "                      to search for significant changes. In some cases, this may be sufficient.\n",
      "        \n",
      "            Basin-Hopping Input Noise:\n",
      "                Some functions have many local minima, causing SPSA and similar methods to run\n",
      "                into bad solutions. This can, to some extent, be countered using `spsa.with_input_noise`.\n",
      "        \n",
      "                    def f(x):\n",
      "                        return ...\n",
      "        \n",
      "                    x = spsa.optimize(spsa.with_input_noise(f, shape, noise=0.5), ...)\n",
      "        \n",
      "                In this way, SPSA will explore neighboring inputs instead of getting stuck in a \"basin\".\n",
      "                If the noise is sufficiently high, and there is a general trend in the direction of the\n",
      "                basins towards the best basin, then this will converge to the locally best basin.\n",
      "        \n",
      "                NOTE: Not all functions perform better with input noise, some may perform worse.\n",
      "        \n",
      "            Stochastic vs Deterministic Functions:\n",
      "                SPSA does not require deterministic functions.\n",
      "        \n",
      "                If it is more efficient to use a stochastic (random) function e.g. by using a random\n",
      "                sample in a dataset each time instead of the whole dataset, then do that instead.\n",
      "        \n",
      "                High-precision accuracy is not possible in this case, but you will get more out of\n",
      "                your calculations this way.\n",
      "        \n",
      "                Running a few iterations afterwards with a deterministic variant, if reasonable, can\n",
      "                be used to get high-precision accuracy if needed.\n",
      "        \n",
      "            Controllable Stochastic Functions:\n",
      "                If the \"noise\" in the function can be controlled by a second parameter, then the\n",
      "                performance of SPSA can be significantly improved by making every pair of calls\n",
      "                use the same \"noise parameter\". This can be implemented as follows:\n",
      "        \n",
      "                    from functools import partial\n",
      "        \n",
      "                    def rng_iterator():\n",
      "                        while True:\n",
      "                            random_value = ...  # A sample from a dataset for example.\n",
      "                            yield random_value\n",
      "                            yield random_value\n",
      "        \n",
      "                    def f(x, rng):\n",
      "                        random_value = next(rng)\n",
      "                        return ...\n",
      "        \n",
      "                    x = spsa.optimize(partial(f, rng=rng_iterator()), ...)\n",
      "        \n",
      "            Twice Differentiable:\n",
      "                It is not required, but it would be good if the objective function is twice\n",
      "                differentiable. SPSA assumes the objective function is relatively smooth in\n",
      "                order to converge well. Otherwise it will struggle to move around points\n",
      "                where the function is not very smooth.\n",
      "        \n",
      "                For stochastic functions, it is expected that the expected value is smooth.\n",
      "        \n",
      "        Parameters\n",
      "        -----------\n",
      "            f:\n",
      "                The function being optimized. Called as `f(array) -> float`.\n",
      "        \n",
      "            x:\n",
      "                The initial point used. This value is edited and returned.\n",
      "        \n",
      "            adam:\n",
      "                True to use Adam, False to not use it.\n",
      "        \n",
      "            iterations:\n",
      "                The number of iterations ran.\n",
      "        \n",
      "            lr:\n",
      "            lr_decay:\n",
      "            lr_power:\n",
      "                If no learning rate is given, then a crude estimate is found using line search.\n",
      "        \n",
      "                The learning rate controls the speed of convergence.\n",
      "        \n",
      "                    lr = lr_start / (1 + lr_decay * iteration) ** lr_power\n",
      "                    x -= lr * gradient_estimate\n",
      "        \n",
      "                Furthermore, the learning rate is automatically tuned every iteration to produce\n",
      "                improved convergence and allow flexible learning rates.\n",
      "        \n",
      "            px:\n",
      "            px_decay:\n",
      "            px_power:\n",
      "                If no px is given, then a crude estimate is found based on the noise in f.\n",
      "        \n",
      "                The perturbation size controls how large of a change in x is used to measure changes in f.\n",
      "        \n",
      "                    px = px_start / (1 + px_decay * iteration) ** px_power\n",
      "                    dx = px * random_signs\n",
      "                    df = (f(x + dx) - f(x - dx)) / 2\n",
      "                    gradient ~ df / dx\n",
      "        \n",
      "                Furthermore, the perturbation size is automatically tuned every iteration to produce\n",
      "                more accurate gradient approximations, reducing chaotic behavior.\n",
      "        \n",
      "            momentum:\n",
      "                The momentum controls how much of the gradient is kept from previous iterations.\n",
      "        \n",
      "            beta:\n",
      "                A secondary momentum, which should be much closer to 1 than the other momentum.\n",
      "                This is used by the Adam method.\n",
      "        \n",
      "            epsilon:\n",
      "                Used to avoid division by 0 in the Adam method.\n",
      "        \n",
      "        Returns\n",
      "        --------\n",
      "            x:\n",
      "                The estimated minimum of f.\n",
      "    \n",
      "    with_input_noise(f: Callable[[numpy.ndarray], float], /, shape: Tuple[int, ...], noise: float) -> Callable[[numpy.ndarray], float]\n",
      "        Adds noise to the input before calling.\n",
      "\n",
      "DATA\n",
      "    __all__ = ['aio', 'amp', 'executor', 'iterator', 'maximize', 'minimize...\n",
      "    executor = <concurrent.futures.process.ProcessPoolExecutor object>\n",
      "\n",
      "VERSION\n",
      "    0.1.2\n",
      "\n",
      "FILE\n",
      "    /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/spsa/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(spsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b137cbac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
